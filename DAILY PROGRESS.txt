Day-wise Progress
ðŸŸ¢ Day 1 â€” Project Setup & Entry Point

On Day 1, the focus was on setting up a strong project foundation following production-style Python and Linux scripting practices.

I set up the project in a Linux/WSL environment using Python 3.x and created an isolated virtual environment to manage dependencies safely. The project structure was designed around a clear processing pipeline, with separate directories for ingestion, parsing, feature extraction, detection, scoring, and reporting.

I implemented a clean entry point (analyser.py) that acts as an orchestrator for the entire pipeline. This script handles command-line arguments, loads configuration from a YAML file, initializes structured logging, and controls the execution flow through a well-defined main() function. Configuration values such as log paths and log levels were externalized into config/config.yaml, making the system fully config-driven.

By the end of Day 1, the project could run end-to-end with proper logging, configuration loading, and a stable execution skeleton, ready for functional modules to be plugged in.

ðŸŸ¢ Day 2 â€” Log Ingestion & Python Packaging

On Day 2, I implemented the log ingestion layer and resolved Python packaging concerns to make the project scalable and modular.

I created a dedicated ingestion module (ingestion/reader.py) responsible solely for reading log files. The ingestion logic was implemented using a generator to stream log files line by line, ensuring memory-efficient handling of large Linux log files. Empty lines and missing files are handled gracefully with proper logging and error handling.

To avoid permission issues with system logs during development, I created a sample authentication log file (sample_logs/auth.log) containing realistic Linux log entries. The log path is read dynamically from the YAML configuration file, keeping the ingestion process configurable and environment-agnostic.

I then integrated the ingestion module into the main execution pipeline and validated it by counting and logging the number of log lines read. During this process, I structured the project as a proper Python package by adding __init__.py files and executed the project using python -m analyser to ensure correct module resolution. This eliminated import errors without relying on unsafe path modifications.

By the end of Day 2, the project successfully executed end-to-end with a working streaming log ingestion layer, clean Python packaging, and verified pipeline integration.